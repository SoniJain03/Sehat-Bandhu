# -*- coding: utf-8 -*-
"""Disease_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nd6v6CmepoYDsd0FC9AHBDwS0XAIz1T-
"""

# Step 1: Install missing libs (only for Colab)
!pip install imbalanced-learn

# Step 2: Import required libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay, precision_recall_curve, auc
from imblearn.over_sampling import SMOTE
import joblib

# Load your dataset
df = pd.read_csv("/content/india_kerala_expanded_symptoms_top30cols.csv")

# Check basic info
print(df.shape)
print(df.head())

# Check class balance
print(df['diseases'].value_counts())

# Drop the target column and get symptom features
symptoms = [col for col in df.columns if col.lower() != "diseases"]

print("Total symptoms:", len(symptoms))
print("\nSymptom list:\n")
for i, symptom in enumerate(symptoms, start=1):
    print(f"{i}. {symptom}")

X = df.drop(columns=['diseases'])
y = df['diseases']

# Handle categorical variables if present
X = pd.get_dummies(X)

# Count samples per disease
class_counts = df['diseases'].value_counts()

# Drop diseases with fewer than 3 samples
rare_classes = class_counts[class_counts < 3].index
print("Dropping these rare classes (less than 3 samples):", list(rare_classes))

df_filtered = df[~df['diseases'].isin(rare_classes)]

# Define Features and Target
X = df_filtered.drop(columns=['diseases'])
y = df_filtered['diseases']

# Encode categorical variables (if any)
X = pd.get_dummies(X)

print("Remaining classes:", y.nunique())
print("Samples per class after filtering:\n", y.value_counts())

from sklearn.model_selection import train_test_split
from imblearn.over_sampling import RandomOverSampler

# Train-Test split (stratified to preserve class distribution)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Use RandomOverSampler instead of SMOTE (works with very small classes)
ros = RandomOverSampler(random_state=42)
X_train_res, y_train_res = ros.fit_resample(X_train, y_train)

print("Before Oversampling:\n", y_train.value_counts())
print("After Oversampling:\n", y_train_res.value_counts())

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(
    n_estimators=200,
    random_state=42,
    class_weight="balanced"  # still helps even though we balanced
)
rf.fit(X_train_res, y_train_res)

y_pred = rf.predict(X_test)

from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred, labels=rf.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rf.classes_)
disp.plot(xticks_rotation=90, cmap="Blues", colorbar=False)
plt.title("Confusion Matrix - Random Forest")
plt.show()

# Classification Report
print("Classification Report:\n")
print(classification_report(y_test, y_pred))

from sklearn.preprocessing import label_binarize
from sklearn.metrics import precision_recall_curve, auc
import matplotlib.pyplot as plt

# Binarize test labels for multi-class Precision–Recall
y_test_bin = label_binarize(y_test, classes=rf.classes_)
y_score = rf.predict_proba(X_test)

plt.figure(figsize=(12,8))

for i, class_name in enumerate(rf.classes_):
    precision, recall, _ = precision_recall_curve(y_test_bin[:, i], y_score[:, i])
    pr_auc = auc(recall, precision)
    plt.plot(recall, precision, lw=2, label=f"{class_name} (AUC={pr_auc:.2f})")

plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision–Recall Curves for Each Disease")
plt.legend(bbox_to_anchor=(1.05, 1), loc="upper left")
plt.grid(True)
plt.show()

import joblib

# Save the trained model
joblib.dump(rf, "random_forest_model.pkl")

print("Model saved as random_forest_model.pkl")

# --- Later, to load the model again ---
# rf_loaded = joblib.load("random_forest_model.pkl")
# y_pred_loaded = rf_loaded.predict(X_test)

